---
title: "Book Recommender System"
author: "Tino Muzambi"
format: 
  html:
    embed-resources: true
    page-layout: full
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, include=FALSE}
# Libraries
install.if.missing <- function(package.name) {
  if (!require(package.name, character.only = TRUE)) {
    install.packages(package.name)
    library(package.name, character.only = TRUE)
  }
}

install.if.missing("tidyverse")
```

# The Data

The data we will be working with is a partially preprocessed version of the ”Book-Crossing” dataset. The data can be downloaded [here](https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset/) from Kaggle. It was collected by Cai-Nicolas Ziegler in a 4-week crawl (August / September 2004) from the Book-Crossing community with kind permission from Ron Hornbaker, CTO of Humankind Systems. It contains 278 858 users (anonymised but with demographic information) providing 1 149 780 ratings (explicit / implicit) about 271 379 books.

```{r}
# Load the data
ratings <- read.csv("data/Ratings.csv")
books <- read.csv("data/Books.csv")
users <- read.csv("data/Users.csv")

head(ratings)
head(books)
head(users)
```

# Data Preprocessing

Before we can merge the data, for performance reasons, we will only sample 10 000 ratings. We will then merge the data into a single dataframe.
```{r}
# Sample 10 000 ratings
set.seed(50731)
ratings <- ratings[sample(nrow(ratings), 10000),]

# Merge the data
comb.ratings <- ratings %>% 
  left_join(books, by = "ISBN") %>% 
  left_join(users, by = "User.ID")
```



Explore the structure of the combined data.

```{r}
str(comb.ratings)

summary(comb.ratings)
```

Looking at the data, we identify some cleaning that needs to be done. We will do the following to clean up the data:

-   Remove the columns that we do not need

-   Replace ages less than 13 and greater than 100 with NA

-   Convert the data types of the columns to the appropriate types

-   Replace year of publication with NA where it is before 1900

```{r}
# Perform data cleaning
comb.ratings <- comb.ratings %>% 
  select(-c("Image.URL.S", "Image.URL.M", "Image.URL.L")) %>% 
  mutate(Age = ifelse(Age < 13 | Age > 100, NA, Age)) %>% 
  mutate(Year.Of.Publication = as.numeric(Year.Of.Publication)) %>% 
  mutate(Year.Of.Publication = ifelse(Year.Of.Publication < 1900, NA, Year.Of.Publication))

summary(comb.ratings)
```

# Exploratory Data Analysis
We will now perform some exploratory data analysis to understand the data better.

```{r}
# Plot the distribution of ratings, age and year of publication faceted
comb.ratings %>% 
  gather(key = "key", value = "value", Book.Rating, Age, Year.Of.Publication) %>% 
  ggplot(aes(x = value)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  labs(title = "Distribution of Key Variables", x = "Value", y = "Count") +
  facet_wrap(~key, scales = "free") +
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5))
```
We observe a large number of zero ratings. This can be attributed to the fact that a majority of the users posting reviews are doing so because they had a bad experience. Alternatively the users, or the site the data is derived from, could be configured to automatically input a 0 for the book rating. This is something we will need to consider when building our recommendation system.

# Recommendation Systems
We will now begin building our recommendation system. We will start by building a user-based collaborative filtering system. We will then build an item-based collaborative filtering system. Finally, we will build a matrix factorisation system.

## User-Based Collaborative Filtering
```{r}
# Function to calculate similarity between users
calculate.user.similarity <- function(user1, user2) {
  common.books <- intersect(user1$ISBN, user2$ISBN)
  if (length(common.books) == 0) return(0)
  
  ratings1 <- user1$Book.Rating[user1$ISBN %in% common.books]
  ratings2 <- user2$Book.Rating[user2$ISBN %in% common.books]
  
  return(cor(ratings1, ratings2, use = "complete.obs"))
}
```

```{r}
# Function to get top N similar users
get.top.similar.users <- function(target.user, all.users, n = 5) {
  similarities <- sapply(all.users, function(user) {
    calculate.user.similarity(target.user, user)
  })
  
  top.users <- head(sort(similarities, decreasing = TRUE), n)
  return(top.users)
}
```

```{r}
# Function to predict rating for a book
predict.rating <- function(target.user, book.isbn, similar.users, all.users) {
  weighted.sum <- 0
  similarity.sum <- 0
  
  for (user.id in names(similar.users)) {
    user <- all.users[[user.id]]
    similarity <- similar.users[user.id]
    
    if (book.isbn %in% user$ISBN) {
      rating <- user$Book.Rating[user$ISBN == book.isbn]
      weighted.sum <- weighted.sum + similarity * rating
      similarity.sum <- similarity.sum + similarity
    }
  }
  
  if (similarity.sum == 0) return(NA)
  
  predicted.rating <- weighted.sum / similarity.sum
  return(predicted.rating)
}
```

```{r}
# Main function for user-based collaborative filtering
user.based.cf <- function(comb.ratings, target.user.id, n.similar.users = 5) {
  # Split data by user
  users.list <- split(comb.ratings, comb.ratings$User.ID)
  
  # Get target user
  target.user <- users.list[[as.character(target.user.id)]]
  
  # Find similar users
  similar.users <- get.top.similar.users(target.user, users.list, n.similar.users)
  
  # Predict ratings for books not rated by target user
  all.books <- unique(comb.ratings$ISBN)
  target.user.books <- target.user$ISBN
  books.to.predict <- setdiff(all.books, target.user.books)
  
  predictions <- sapply(books.to.predict, function(book) {
    predict.rating(target.user, book, similar.users, users.list)
  })
  
  # Create a data frame with predictions
  recommendations <- data.frame(
    ISBN = books.to.predict,
    Predicted.Rating = predictions
  )
  
  recommendations <- recommendations[order(recommendations$Predicted.Rating, decreasing = TRUE), ]
  return(recommendations)
}
```

